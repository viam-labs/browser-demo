<!DOCTYPE html>
<html>
  <head>
    <meta name="viewport" content="user-scalable=no, initial-scale=1, maximum-scale=1, minimum-scale=1, width=device-width, height=device-height, target-densitydpi=device-dpi" />
    <title>Viam Demo</title>
    <link rel="icon" href="favicon.ico" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/purecss@3.0.0/build/pure-min.css" integrity="sha384-X38yfunGUhNzHpBaEBsWLO+A0HDYOQi8ufWDkZ0k9e0eXz/tH3II7uKZ9msv++Ls" crossorigin="anonymous">
    <link href="styles.css" rel="stylesheet">
    <link href="prism.css" rel="stylesheet" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
  </head>
  <body>
    <script type="module" src="main.js"></script>
    <script src="prism.js"></script>

    <div id="layout">
      <!-- Menu toggle -->
      <a href="#menu" id="menuLink" class="menu-link">
        <!-- Hamburger icon -->
        <span></span>
      </a>
  
      <div id="menu">
          <div class="pure-menu">
              <a class="pure-menu-heading pure-menu-selected" href="#home" id="home_select">Viam Labs</a>
  
              <ul class="pure-menu-list">
                <li class="pure-menu-item" id="system_select"><a href="#system"  class="pure-menu-link">System monitoring</a></li>
                  <li class="pure-menu-item" id="object_select"><a href="#object"  class="pure-menu-link">Object detection and TTS</a></li>
                  <li class="pure-menu-item" id="gesture_select"><a href="#gesture"  class="pure-menu-link">Gesture detection and LLMs</a></li>
                  <li class="pure-menu-item" id="vlm_select"><a href="#vlm"  class="pure-menu-link">STT and VLMs</a></li>

                  <li class="pure-menu-item" id="more_select">
                      <a href="#more" class="pure-menu-link">Try more</a>
                  </li>
                </ul>
          </div>
      </div>

      <div id="main">
        <div class="header"><h1>Viam Resource Playground</h1></div>

        <div class="content" id="home_content">
          <div class="pure-g">
            <div class="pure-u-1-2">
              <p><a href="https://viam.com">Viam</a> is a platform that allows you to compose a smart machine or robotics project from any number of components or services through configuration.</p>
              <p>
                Components typically represent physical hardware, while services represent higher-level functionality - often integrating with physical hardware or other technologies like Machine Learning, Artificial Intelligence, or external APIs.
                Viam components and services that are configured as part of a machine can be used securely with APIs in popular programming languages.
              </p> 
              <p>
                This playground allows you to interact with a number of built-in and modular Viam resources running on a viam-server instance in Google Cloud Platform (GCP) through Viam's TypeScript SDK.
                Note that video and audio capture is used in some demos, so your browser will ask for permission.
              </p>
              </div>
              <div class="pure-u-1-2" style="padding-top: 10px;">
                <img src="images/viam.png"/>
              </div>
          </div>
          <p>
            Click on the menu to choose a specific demo, or go to the first demo: <a href="/#system" onclick="document.getElementById('system_select').click();">System monitoring</a>
          </p>
        </div>

        <div class="content" id="system_content" style="display: none;">
          <p>Here, we are getting real-time system data from the server running Viam using a <a href="https://app.viam.com/module/aleparedes/viam-telegraf-sensor">module from the Viam registry</a> that provides a <a href="https://www.influxdata.com/time-series-platform/telegraf/">Telegraf</a> sensor component.
          You can use data collected from this or other modules to create realtime monitoring or management dashboards, and also collect and use this data with Viam's <a href="https://docs.viam.com/data/">Data Management</a> solution.
          </p>
          <div class="pure-g">
            <div class="pure-u-1-3">
              <p>
              <table class="pure-table" id="system_table"></table>
              </p>
            </div>
            <div class="pure-u-2-3">
              <p style="padding-left: 1em;">
                This in-browser demo is using the <a href="https://ts.viam.dev/">Viam Typescript SDK</a>.
                We are using Viam's <a href="https://docs.viam.com/components/sensor/#api">Sensor API</a> to retrieve system stats from the Telegraf module:
              </p>
              <div style="height:140px;width:570px;overflow:auto;padding-left: 1em;">
<pre><code class="language-javascript">import { createRobotClient, SensorClient } from '@viamrobotics/sdk';
client = createRobotClient({...});
const system_monitor = new SensorClient(client, 'telegraf');
const stats = await system_monitor.getReadings();
// now do something with the stats like display in a table
              </code></pre></div>
              <p style="padding-left: 1em;">
                Viam has a number of other programming language <a href="https://docs.viam.com/sdks/">SDKs</a> that you can use with your projects to interact with components and services.
                For example, code with the same functionality would look like this in Python:
              </p>
              <div style="height:160px;width:570px;overflow:auto;padding-left: 1em;">
<pre><code class="language-python">from viam.robot.client import RobotClient
from viam.components.sensor import Sensor
client = await RobotClient.at_address(...)
system_monitor = Sensor.from_robot(client, 'telegraf')
stats = await system_monitor.get_readings()
# now do something with the stats
                </code></pre></div>
            </div>
          </div>
        </div>

        <div class="content" id="object_content" style="display: none;">
          <p>
            Each Viam <a href="https://docs.viam.com/components/">component</a> and <a href="https://docs.viam.com/services/">service</a> implements an <a href="https://docs.viam.com/build/program/apis/">API</a>, providing an interface that is consistent across all models of that resource.
            One type of built-in service that Viam provides is a <a href="https://docs.viam.com/ml/vision/">Vision Service</a>, and all models of the Vision Service implement the <a href="https://docs.viam.com/ml/vision/#api">rdk:service:vision API</a>.
            This API provides methods such as GetDetections() and GetDetectionsFromCamera().
          <p>  
            Select one of the detectors below to use it with images from your device's webcam.
            Each time a new class is detected, we'll use the TTS (text to speech) capability of the <a href="https://app.viam.com/module/viam-labs/speech">speech module</a> from Viam's <a href="https://docs.viam.com/registry/">registry</a> to say what is seen out-loud.     
          </p> 

            <div class="pure-g">
              <div class="pure-u-1-3">
                <p style="padding-top: .7em;">
                <select name="detector-select" id="detector-select">
                  <option value="coco-detector">efficientdet ML detector</option>
                  <option value="red-detector">Color red detector</option>
                  <option value="face-detector">Deepface facial detector</option>
                </select>
                <button id="click-photo">Select</button>
                <br/><br/>
                <canvas id="canvas" hidden width="300" height="280"></canvas>
                <canvas id="finalCanvas" width="300" height="280"></canvas>
              </div>
              </p>
              <div class="pure-u-2-3">
                <p>
                  <p id="coco-detector-desc" style="display:block;padding-left: 1em;">The efficientdet detector is a popular Machine Learning object detector based on the COCO open-source dataset. This detector is in tflite format and can be found <a href="https://app.viam.com/ml-model/viam-labs/EfficientDet-COCO">on the Viam registry</a>.</p>
                  <p id="red-detector-desc" style="display:none;padding-left: 1em;">The red detector is a heuristics-based color detector and a model that is built-in to the Viam platform.</p>
                  <p id="face-detector-desc" style="display:none;padding-left: 1em;">The face detector is an ML model <a href="https://app.viam.com/module/viam-labs/facial-detector">from the Viam registry</a> that integrates the <a href="https://github.com/serengil/deepface">DeepFace</a> library.</p>
                  <p style="padding-left: 1em;">
                    Viam's <a href="https://docs.viam.com/ml/vision/">Vision API</a> is being used to get detections.
                    Regardless of the model, the API method GetDetections() is called.
                  </p>
                  <div style="height:300px;width:595px;overflow:auto;padding-left: 1em;">
<pre><code class="language-javascript" style="display:block">import { createRobotClient, VisionClient } from '@viamrobotics/sdk';
import { SpeechClient } from 'speech-service-api';
client = createRobotClient({...});

const speech = new SpeechClient(client, "speechio");
</code><code id="coco-detector-code" class="language-javascript" style="display:block">const detector = new VisionClient(client, 'coco-detector');</code><code id="red-detector-code" class="language-javascript" style="display:none">const detector = new VisionClient(client, 'red-detector');</code><code id="face-detector-code" class="language-javascript" style="display:none">const detector = new VisionClient(client, 'face-detector');</code><code class="language-javascript" style="display:block">
let detections = await detector.getDetections(image, 300, 280, 'image/jpeg');
if (detections[0] && detections[0].confidence > .6) {
  let sp = await speech.toSpeech("I see a " + detections[0].className);
  const audioBuffer = await decoders.mp3(sp);
  play(audioBuffer);
}
                  </code>
                </pre></div>

                </p>
              </div>
          </div>
          </div>

        <div class="content" id="gesture_content" style="display: none;">
          <p>
            Smart machines you build on the Viam platform can be extended with resources from elsewhere.
            In this demo, we are using a gesture detection <a href="https://huggingface.co/lewiswatson/yolov8x-tuned-hand-gestures">model 
            from HuggingFace</a> managed by the <a href="https://app.viam.com/module/viam-labs/YOLOv8">YOLOv8 vision service</a> from the Viam registry to detect letters in ASL (American Sign Language).
          </p>
          <p>
            Try making some of the signs to spell a word or words, <b>ending with the letter V (looks like the "peace" sign) 2 times</b>. 
            Once this has been detected, we will use the <a href="https://huggingface.co/pansophic/rocket-3B">Rocket 3b</a> LLM (large language model) 
            deployed to our machine with the <a href="https://app.viam.com/module/viam-labs/local-llm">local-llm</a> module from the Viam registry to create a response based on those words.
          </p>
          <div class="pure-g">
            <div class="pure-u-1-3">
              <img src="images/asl_letters.jpeg" style="width: 280px;height: 400px;"/>
            </div>
            <div class="pure-u-2-3">
              <div class="pure-g">
                <div class="pure-u-1-2" style="height: 150px;">
                  <b>Detected:</b>
                  <div id="asl_words" style="height:100px;overflow-wrap: break-word;overflow-y: scroll;"></div>
                </div>
                <div class="pure-u-1-2" style="height: 150px;">
                  <b>Response:</b>
                  <div id="asl_completion" style="height:130px;overflow-wrap: break-word;overflow-y: scroll;"></div>
                </div>
              </div>
<br/>
              <div style="height:500px;width:580px;overflow:auto;padding-left: 1em;">
<pre><code class="language-javascript" style="display:block">import { createRobotClient, VisionClient } from '@viamrobotics/sdk';
import { ChatClient } from 'chat-service-api';
const client = createRobotClient({...});
const asl_detector = new VisionClient(client, "asl_detector");
const llm = new ChatClient(client, "llm");

let completed = false;
let last_seen = "";
let letters = "";
const chat_prefix = "Create an acronym from the letters ";
while (!completed) {
  let detections = await asl_detector.getDetections(image, 300, 280, 'image/jpeg');
  if (detections[0] && detections[0].confidence > .8) {
    if (detections[0].className == 'V' && last_seen == 'V') {
      let completion = await llm.chat(chat_prefix + letters);
      completed = true;
    }
    else {
      last_seen = detections[0].className;
      letters = letters + detections[0].className;
    }
  }
}
                </code></pre></div>
            </div>
          </div> 
        </div>


        <div class="content" id="vlm_content" style="display: none;">
          <p>
            Vision language models (VLMs) extend traditional LLMs by incorporating the ability to interpret images.
            We can run small VLMs like <a href="https://github.com/vikhyat/moondream">Moondream</a> (or larger VLMs!)
            with Viam, in this case managed by the <a href="https://app.viam.com/module/viam-labs/moondream-vision">moondream-vision service</a> from the Viam registry.
          </p>
          <p>
            Choose one of the images, or capture one from your webcam.
            Then, hold down the "Ask Question" button and ask a question about the photo like "Where is the dog?" aloud. 
            We will use the <a href="https://app.viam.com/module/viam-labs/speech">Speech module</a> from the Viam registry to convert your question speech to text (STT), 
            then send that to the Moondream VLM for a response.
          </p>
          <div class="pure-g">
            <div class="pure-u-1-3">
              
              <a href="#vlm" id="captureForVLM">Use webcam image</a> or click one below
              <div style="border: 1px; border-style:solid; width: 280px; height: 220px;">
                <canvas id="VLMImage" width="280" height="220"></canvas>
              </div>
              <br/>
              <div class="pure-g">
                <div class="pure-u-1-2">
                  <img src="images/dog_lake.jpg" id="vlm_dog" style="width:120px;height:150px;"/>
                </div>
                <div class="pure-u-1-2">
                  <img src="images/bread.jpg" id="vlm_bread" style="width:120px;height:150px;"/>
                </div>
              </div>

              <div class="pure-g">
                <div class="pure-u-1-2">
                  <img src="images/car_building.jpg" id="vlm_car" style="width:120px;height:150px;"/>
                </div>
                <div class="pure-u-1-2">
                  <img src="images/balance.jpg" id="vlm_balance" style="width:120px;height:150px;"/>
                </div>
              </div>

              <div class="pure-g">
                <div class="pure-u-1-2">
                  <img src="images/flowers.jpg" id="vlm_flowers" style="width:120px;height:150px;"/>
                </div>
                <div class="pure-u-1-2">
                  <img src="images/party.jpg" id="vlm_party" style="width:120px;height:150px;"/>
                </div>
              </div>
            </div>
            <div class="pure-u-2-3">
              <div style="padding-left: 20px;"><a class="pure-button pure-button-disabled" id="vlmRecordQuestion" href="#vlm">Hold and ask question</a>

              <div class="pure-g">
                <div class="pure-u-1-2" style="height: 150px;">
                  <b>Question:</b>
                  <div id="vlm_question" style="height:100px;overflow-wrap: break-word;overflow-y: scroll;"></div>
                </div>
                <div class="pure-u-1-2" style="height: 150px;">
                  <b>Response:</b>
                  <div id="vlm_completion" style="height:130px;overflow-wrap: break-word;overflow-y: scroll;"></div>
                </div>
              </div>
            </div>
<br/>
              <div style="height:480px;width:600px;overflow:auto;padding-left: 1em;">
<pre><code class="language-javascript" style="display:block">import { createRobotClient, VisionClient } from '@viamrobotics/sdk';
import { SpeechClient } from 'speech-service-api';
const client = createRobotClient({...});
const vlm_classifier = new VisionClient(client, "moondream-classifier");
const speech = new SpeechClient(client, "speechio");

// capture audio, in this case via browser functionality
const capturedAudioArray = captureAudio()
const speechText = await speech.toText(capturedAudioArray, "wav")
let classifications = 
  await vlm_classifier.getClassifications(theImage, 300, 280, 
                        "image/jpeg", 1, {"question": speechText});

let vlmResponse = classifications[0].className;
// now we can print out the response from the VLM
</code></pre></div>
            </div>
          </div> 
        </div>

        <div class="content" id="more_content" style="display: none;">
          <div class="pure-g">
            <div class="pure-u-1-2">
              <p>
                <img src="images/viam_robot.png" style="width:300px"/>
              </p>
            </div>
            <div class="pure-u-1-2">
              <p>
                Now that you've gotten hands-on with some Viam platform configurations and capabilities, we are excited to see how you might use Viam to accelerate your projects.
              </p>
              <p>
                Viam is at its core an open source platform, and you get started with our secure in-cloud data and fleet management solutions for free (and continue with <a href="https://viam.com/product/pricing">transparent consumption-based pricing</a>).
              </p>
              <p>
                How will you use Viam to revolutionize your hardware projects?
              </p>
              <p>
                <ul>
                  <li><a href="https://www.viam.com/resources/try-viam">Control a robotic rover running in Viam's office</a></li>
                  <li><a href="https://viam.com/blog">Check out the Viam blog</a></li>
                  <li><a href="https://docs.viam.com/">Read more in the Viam documentation</a></li>
                  <li><a href="https://discord.gg/viam">Join our Discord community</a></li>
                </ul>
              </p>
            </div>
          </div>
        </div>


      </div>
    </div>

  </body>
</html>
